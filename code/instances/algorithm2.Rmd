---
title: "Results: Algorithm 2"
output: html_document
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) { 
    out_dir <- '../../docs/';
    rmarkdown::render(inputFile,
                      encoding=encoding, 
                      output_file=file.path(dirname(inputFile), out_dir, 'algorithm2.html')) })
---

<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r setup, include=FALSE}
here::i_am("code/instances/algorithm2.Rmd")  # specify relative path given project
# remotes::install_github("relund/gMOIP")
# library(gMOIP)
#library(DT)
library(tidyverse)
library(ggplot2)
# library(knitr)
# library(rgl)
# rgl::setupKnitr()
# options(rgl.useNULL=TRUE)
# rgl::par3d("family" = "serif")
# library(tikzDevice)
knitr::opts_chunk$set(
  echo = FALSE,
  message=FALSE, include = TRUE, warning = FALSE,
  out.width = "69%", fig.width = 12, fig.align = "center", fig.asp = 0.8
)
```


```{r, eval=FALSE}
cat("Update statistics for results.")
paths <- fs::dir_ls(here::here("code/instances/results"), recurse = T, type = "file", glob = "*prob*.json")
prefix <- str_extract(paths, ".*/")

filename <- str_extract(paths, "^.*/(.*)$", group = 1)
alg <- unique(str_extract(filename, "(.*?)-", group = 1))
head(alg)


a <- "alg2"

algPaths <- str_subset(paths, a)
head(algPaths)
datRes <- NULL

for (i in 1:length(algPaths)) {
   algFile <- algPaths[i]
   algFile
   lstAlg <- jsonlite::read_json(algFile, simplifyVector = F)
   row <- lstAlg[[2]]
   row$MGS_sizes <- paste(row$MGS_sizes, collapse = "-")
   datRes <- datRes %>% bind_rows(row)
}
write_csv(datRes, here::here("code/instances/stat-alg2.csv"))
```


```{r, eval=FALSE}
cat("Update statistics for results.")
paths <- fs::dir_ls(here::here("code/instances/results/algorithm2"), recurse = T, type = "file", glob = "*prob*.json")
prefix <- str_extract(paths, ".*/")

filename <- str_extract(paths, "^.*/(.*)$", group = 1)
alg <- unique(str_extract(filename, "(.*?)-", group = 1))
head(alg)


a <- "MGS-"

algPaths <- str_subset(paths, a)
head(algPaths)
datRes <- NULL

for (i in 1:length(algPaths)) {
   algFile <- algPaths[i]
   algFile
   lstAlg <- jsonlite::read_json(algFile, simplifyVector = F)
   row <- lstAlg[[2]]
   row$MGS_sizes <- paste(row$MGS_sizes, collapse = "-")
   row$MGS_sizes_se <- paste(row$MGS_sizes_se, collapse = "-")
   row$MGS_sizes_sne <- paste(row$MGS_sizes_sne, collapse = "-")
   row$MGS_sizes_us <- paste(row$MGS_sizes_us, collapse = "-")
   row$prob_sizes_se <- paste(row$prob_sizes_se, collapse = "-")
   row$prob_sizes_sne <- paste(row$prob_sizes_sne, collapse = "-")
   row$prob_sizes_us <- paste(row$prob_sizes_us, collapse = "-")
   #row$prob_sizes_us_total <- paste(row$prob_sizes_us, collapse = "-")
   datRes <- datRes %>% bind_rows(row)
}
write_csv(datRes, here::here("code/instances/stat-alg2.csv"))
```

```{r}
dat <- read_csv(here::here("code/instances/stat-alg2.csv"))

```

```{r, eval=FALSE}
head(dat)
```




Total time used in computing minimum generator sets (MGS)

*Hours used: `r sum(dat$running_time) /60 / 60`*


*Note:*

For all the experiments the minimum generator sets are unique. In particular every generator $\mathcal{G}$ with corrosponding set $$ (\mathcal{Y}^1, \mathcal{Y}^2... \mathcal{Y}^S)$$ we have:
$$ \mathcal{Y} = \left\{ y^s \vert \exists y \in \mathcal{Y}_N, c_s = y^s, \forall c \in \mathcal{C}(y) \right\} $$
This also implies that the found minimum generator sets are unique minimal generator sets. This is not generally the case as seen in example [ref generatorNotUnique]. It implies however that minimal generator sets are likely to be unique.



```{r}
# Mutate the filename to columns
dat <- dat %>%
  mutate(method = str_extract(filename, "^.*-(.*)-.*$", group = 1)) %>% 
  mutate(method = map_chr(method, function (x) {
  x <- str_split_1(x, "")
  x <- unique(x)
  str_c(x, collapse = "")
  })) %>%
  mutate(p = str_extract(filename, "-(\\d+)-", group = 1)) %>% 
  mutate(m = str_extract(filename, "-(\\d+)_", group = 1)) %>%
  mutate(rel_size = MGS_size / max_size)  %>%
  mutate(avg_sp_size = max_size / as.numeric(m))  #%>% filter(method != 'l')


dat$m_numeric <- as.numeric(dat$m)
dat$p_numeric <- as.numeric(dat$p)

dat$m <- as.factor(dat$m)
dat$p <- as.factor(dat$p)
```


# STATUS

```{r}
datAllSolved <- dat %>% 
  group_by(p, m, method, avg_sp_size) %>% 
  filter(n() == 5) %>% select(filename, Yn_size) %>% 
   ungroup()
nrow(datAllSolved)
```
 
 
```{r}
# all instances 
paths <- fs::dir_ls(here::here("code/instances/problems"), recurse = T, type = "file", glob = "*prob*.json")
prefix <- str_extract(paths, ".*/")

filename <- str_extract(paths, "^.*/(.*)$", group = 1)
alg <- unique(str_extract(filename, "(.*?)-", group = 1))
#a <- "prob-"
#algPaths <- str_subset(paths, a)
#head(algPaths)

allInstances <- tibble(filename)
allInstances <- tibble(filename) %>% select(filename) %>% mutate(sp_size = as.numeric(str_extract(filename,  "^.*-(.*?)\\|.*$", group = 1))) %>%
  mutate(method = str_extract(filename, "^.*-(.*)-.*$", group = 1)) %>% 
  mutate(method = map_chr(method, function (x) {
    x <- str_split_1(x, "")
    x <- unique(x)
    str_c(x, collapse = "")
  })) 
totalInstances <- allInstances %>% filter(sp_size <= 300) %>% nrow()

unsolved <- right_join(dat, allInstances) %>% filter(sp_size <= 300, is.na(Yn_size)) %>% select(filename, method)
unsolved %>% filter(method != 'l')

```


Solved `r nrow(datAllSolved)` of `r totalInstances``



# MGS size as a function of maximum possible size.
```{r}
dat %>%
   #ggplot(aes(x = max_size, y = MGS_size, color = method)) +
   ggplot(aes(x = method, y = rel_size, color = method)) +
   geom_boxplot() + 
   stat_summary(fun="mean", geom="line") +
   labs(
        y = "Size of MGS relative to total enumeration",
        x = "Method") +
   theme(legend.position = "bottom")
```


```{r}
mean_m <- dat %>% filter(method == 'm') %>% summarise(mean(rel_size))
mean_m_format <- sprintf("%.2f%%", mean_m * 100)
mean_ul <- dat %>% filter(method == 'ul') %>% summarise(mean(rel_size))
mean_ul_format <- sprintf("%.2f%%", mean_ul * 100)
mean_both <- dat %>% filter(method == 'ul' | method == 'm') %>% summarise(mean(rel_size))
remain_format <- sprintf("%.0f%%", (1-mean_both) * 100)


# relative unsupported
mean_rel_unsupport_ul <- dat %>% filter(method == 'ul') %>% summarise((mean(prob_sizes_us_total/max_size)))
mean_rel_unsupport_m <- dat %>% filter(method == 'm') %>% summarise((mean(prob_sizes_us_total/max_size)))
mean_rel_unsupport_u <- dat %>% filter(method == 'u') %>% summarise((mean(prob_sizes_us_total/max_size)))
mean_rel_unsupport_ul_format <- sprintf("%.0f%%", (mean_rel_unsupport_ul) * 100)
mean_rel_unsupport_m_format <- sprintf("%.0f%%", (mean_rel_unsupport_m) * 100)
mean_rel_unsupport_u_format <- sprintf("%.0f%%", (mean_rel_unsupport_u) * 100)


mean_rel_unsupport_ul_format
mean_rel_unsupport_m_format
mean_rel_unsupport_u_format
```


For the instances *l* the MGS tend to consist of all subproblem points. Also for the *u* instances a large number of the subproblem points are used in the minimum generator sets, however the spread is significantly higher than that of *l*, and in some cases for *u* the MGS consists of only half the total subproblem points. 

The instances *m* and *ul* both contain a larger amount of unsupported and supported points. [TODO Show how many approx 50% of each?]. The difference between the instances are that for *m* each subset consists of a mix of supported and unsupported points, while the *ul* instances consists of subsets which have either many unsupported (*u*), or many supported points (*l*). For *m* and *ul* we find that the MGS is unlikely to consist of all the subproblem points. On average the MGS consists of only `r mean_m_format` of the total subproblem points for *m* instances and `r mean_ul_format` for *ul* instances. This implies that around `r remain_format` of the generated subproblem points are not needed for generating the nondominated sum.
```{r}
# Bar chart the distribution (supported, unsupported) of each MSP instance
```


# Relative size of MGS wrt. average subproblem cardinality


```{r}

# todo fix ribbon
dat %>% filter(m_numeric == 3, p_numeric == 4) %>%
  ggplot(aes(x = max_size, y = (MGS_size/m_numeric), color = method, fill = method)) +
  stat_summary(fun="mean", geom="line") +
  geom_ribbon(aes(ymin = MGS_size_min, ymax = MGS_size_max), alpha = 0.1) +
  geom_line(aes(y = MGS_size/m_numeric), linetype = "dashed") +
  #geom_boxplot() + 
  facet_grid(p ~ m, labeller =  "label_both")  + 
  labs(title = "Relative size of MGS given subproblem cardinality",
       y = "Relative cardinality MGS/Max MGS",
       x = "Average subproblem cardinality",
       color = "Methods used to generate subproblems") +
  theme(legend.position = "bottom") 
```

```{r}


dat %>% 
   #filter(m_numeric == 3, p_numeric == 4) %>%
  ggplot(aes(x = max_size, y = MGS_size/m_numeric, color = method, fill = method)) +
  stat_summary(fun="mean", geom="line") +
  geom_ribbon(aes(ymin = MGS_size_min, ymax = MGS_size_max), alpha = 0.1) +
  #geom_line(aes(y = MGS_size/m_numeric), linetype = "dashed") +
  #geom_boxplot() + 
  geom_point() +
  facet_grid(p ~ m, labeller =  "label_both")  + 
  labs(
#     title = "Relative size of MGS given subproblem cardinality",
#       y = "Relative cardinality MGS/Max MGS",
#       x = "Average subproblem cardinality",
       color = "Methods used to generate subproblems"
     )+
  theme(legend.position = "bottom") 
```

In [above] we see that the relative size of the MGS for the instances *m* and *ul* decrease in the total number of subproblem points and in the number of subproblems.  

For the instances *l* we see that in almost all instances the MGS consists of all subproblem points. 

The *u* exibit a different pattern from the rest. Here we find that for instances $p>3$ the MGS tend to consist of all subproblem points. For the remaining instances we find that like *ul* and *m* the size of MGS is decreasing in the number of subproblems.



# Relative size of MGS wrt. total subproblem cardinality

```{r}
dat %>% 
  ggplot(aes(x = avg_sp_size, y = rel_size, color = method)) +
  geom_point() + 
  #geom_boxplot() + 
  stat_summary(fun="mean", geom="line") +
  facet_grid(p ~ m, labeller =  "label_both")  + 
  labs(title = "Relative of MGS given subproblem cardinality",
       y = "Cardinality MGS relative to max possible size",
       color = "Methods used to generate subproblems") +
  theme(legend.position = "bottom") 
```

# size of Yn (like for alg1)

```{r}
dat %>% 
  ggplot(aes(x = avg_sp_size, y = Yn_size, color = method)) +
  geom_point() + 
  #geom_boxplot() + 
  stat_summary(fun="mean", geom="line") +
  facet_grid(p ~ m, labeller =  "label_both")  + 
  labs(
     title = "size of Yn",
       y = "Size of Yn",
       x = "Avg subproblem cardinality",) + 
  theme(legend.position = "bottom") 
```


# classifications


```{r}
dat %>% 
  ggplot(aes(x = avg_sp_size, y = MGS_sizes_us_avg*m_numeric/prob_sizes_us_total, color = method)) +
  geom_point() + 
  #geom_boxplot() + 
  stat_summary(fun="mean", geom="line") +
  facet_grid(p ~ m, labeller =  "label_both")  + 
  labs(
     title = "Number of us points in MGS relative to total us points in subproblems",
       color = "Methods used to generate subproblems"
     ) +
  theme(legend.position = "bottom") 
```

```{r}
dat %>% 
  ggplot(aes(x = avg_sp_size, y = MGS_sizes_se_avg*m_numeric/prob_sizes_se_total, color = method)) +
  geom_point() + 
  #geom_boxplot() + 
  stat_summary(fun="mean", geom="line") +
  facet_grid(p ~ m, labeller =  "label_both")  + 
  labs(
     title = "Number of supported extreme points in MGS relative to total se points in subproblems",
       color = "Methods used to generate subproblems"
     ) +
  theme(legend.position = "bottom") 
```


```{r}
check_dat <- dat %>% filter(MGS_sizes_se_avg*m_numeric/prob_sizes_se_total < 0.7)
```

